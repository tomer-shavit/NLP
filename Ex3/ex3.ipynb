{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 11.1/11.1 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "Collecting numpy>=1.19.5\n",
      "  Downloading numpy-2.2.0-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tomer\\uni\\nlp\\ex3\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Installing collected packages: threadpoolctl, numpy, scipy, scikit-learn\n",
      "Successfully installed numpy-2.2.0 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T13:16:24.982264Z",
     "start_time": "2024-12-18T13:16:24.978939Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Download the Brown corpus\n",
    "nltk.download('brown')\n",
    "\n",
    "# Load the tagged sentences from the \"news\" category\n",
    "tagged_sents = brown.tagged_sents(categories='news')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T13:16:27.136942Z",
     "start_time": "2024-12-18T13:16:26.831111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/tomershav/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    tagged_sents, test_size=0.1, shuffle=False\n",
    ")\n",
    "\n",
    "# Display dataset sizes\n",
    "print(f\"Number of sentences in training set: {len(train_data)}\")\n",
    "print(f\"Number of sentences in testing set: {len(test_data)}\")\n",
    "\n",
    "# Save the training and testing datasets for further usage\n",
    "with open(\"train_data.pkl\", \"wb\") as train_file, open(\"test_data.pkl\", \"wb\") as test_file:\n",
    "    import pickle\n",
    "    pickle.dump(train_data, train_file)\n",
    "    pickle.dump(test_data, test_file)\n",
    "\n",
    "print(\"Dataset preparation complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T13:16:29.207335Z",
     "start_time": "2024-12-18T13:16:29.078141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in training set: 4160\n",
      "Number of sentences in testing set: 463\n",
      "Dataset preparation complete.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:16:32.238721Z",
     "start_time": "2024-12-18T13:16:32.201807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Compute p(tag|word) using the training set\n",
    "tag_counts = defaultdict(int)\n",
    "word_tag_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sentence in train_data:\n",
    "    for word, tag in sentence:\n",
    "        tag_counts[tag] += 1\n",
    "        word_tag_counts[word][tag] += 1\n",
    "\n",
    "# Step 2: Determine the most likely tag for each word\n",
    "most_likely_tag = {}\n",
    "for word, tags in word_tag_counts.items():\n",
    "    most_likely_tag[word] = max(tags, key=tags.get)\n",
    "\n",
    "# Step 3: Define a function to tag a sentence\n",
    "def tag_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Tags a sentence using the most likely tag baseline.\n",
    "    \"\"\"\n",
    "    tagged_sentence = []\n",
    "    for word in sentence:\n",
    "        # Use the most likely tag for known words; default to 'NN' for unknown words\n",
    "        tag = most_likely_tag.get(word, 'NN')\n",
    "        tagged_sentence.append((word, tag))\n",
    "    return tagged_sentence\n",
    "\n",
    "# Step 4: Evaluate on the test set\n",
    "known_correct = 0\n",
    "unknown_correct = 0\n",
    "known_total = 0\n",
    "unknown_total = 0\n",
    "\n",
    "for sentence in test_data:\n",
    "    words = [word for word, tag in sentence]\n",
    "    true_tags = [tag for word, tag in sentence]\n",
    "\n",
    "    # Predict tags for the sentence\n",
    "    predicted_tags = [tag for word, tag in tag_sentence(words)]\n",
    "\n",
    "    for word, true_tag, predicted_tag in zip(words, true_tags, predicted_tags):\n",
    "        if word in most_likely_tag:  # Known word\n",
    "            known_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                known_correct += 1\n",
    "        else:  # Unknown word\n",
    "            unknown_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                unknown_correct += 1\n",
    "\n",
    "# Step 5: Calculate error rates\n",
    "known_error_rate = 1 - (known_correct / known_total)\n",
    "unknown_error_rate = 1 - (unknown_correct / unknown_total)\n",
    "total_error_rate = 1 - ((known_correct + unknown_correct) / (known_total + unknown_total))\n",
    "\n",
    "# Step 6: Print results\n",
    "print(f\"Known Words Error Rate: {known_error_rate:.4f}\")\n",
    "print(f\"Unknown Words Error Rate: {unknown_error_rate:.4f}\")\n",
    "print(f\"Total Error Rate: {total_error_rate:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Words Error Rate: 0.0832\n",
      "Unknown Words Error Rate: 0.7897\n",
      "Total Error Rate: 0.1639\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:16:40.397134Z",
     "start_time": "2024-12-18T13:16:40.392749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Known Words Error Rate: 0.0832\n",
    "Unknown Words Error Rate: 0.7897\n",
    "Total Error Rate: 0.1639\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKnown Words Error Rate: 0.0832\\nUnknown Words Error Rate: 0.7897\\nTotal Error Rate: 0.1639\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:36:19.063752Z",
     "start_time": "2024-12-18T13:34:58.372477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Step (c)i: Training phase\n",
    "# Compute transition and emission probabilities using Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "# Initialize dictionaries to count occurrences\n",
    "bigram_counts = defaultdict(lambda: defaultdict(int))  # Counts of tag bigrams\n",
    "emission_counts = defaultdict(lambda: defaultdict(int))  # Counts of (word, tag)\n",
    "tag_counts = defaultdict(int)  # Counts of individual tags\n",
    "\n",
    "# Count tag bigrams and emissions from training data\n",
    "for sentence in train_data:\n",
    "    prev_tag = None  # Beginning of a sentence\n",
    "    for word, tag in sentence:\n",
    "        tag_counts[tag] += 1\n",
    "        emission_counts[tag][word] += 1\n",
    "        if prev_tag is not None:\n",
    "            bigram_counts[prev_tag][tag] += 1\n",
    "        prev_tag = tag\n",
    "\n",
    "# Compute transition probabilities P(tag2|tag1) and emission probabilities P(word|tag)\n",
    "transition_probs = defaultdict(lambda: defaultdict(float))\n",
    "emission_probs = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for prev_tag, next_tags in bigram_counts.items():\n",
    "    total_bigrams = sum(next_tags.values())\n",
    "    for next_tag, count in next_tags.items():\n",
    "        transition_probs[prev_tag][next_tag] = count / total_bigrams\n",
    "\n",
    "for tag, words in emission_counts.items():\n",
    "    total_emissions = sum(words.values())\n",
    "    for word, count in words.items():\n",
    "        emission_probs[tag][word] = count / total_emissions\n",
    "\n",
    "# Step (c)ii: Viterbi algorithm without recursion\n",
    "def viterbi_algorithm(sentence, tag_set, transition_probs, emission_probs, unknown_tag='NN'):\n",
    "    \"\"\"\n",
    "    Perform POS tagging using the Viterbi algorithm for a bigram HMM without recursion.\n",
    "    \"\"\"\n",
    "    n = len(sentence)\n",
    "    viterbi = [{} for _ in range(n)]  # Viterbi table: list of dictionaries\n",
    "    backpointer = [{} for _ in range(n)]  # Backpointer table: list of dictionaries\n",
    "\n",
    "    # Initialization for the first word\n",
    "    for tag in tag_set:\n",
    "        viterbi[0][tag] = (\n",
    "            transition_probs.get(None, {}).get(tag, 1e-10)  # Start transition probability\n",
    "            * emission_probs.get(tag, {}).get(sentence[0], 1e-10)  # Emission probability\n",
    "        )\n",
    "        backpointer[0][tag] = None\n",
    "\n",
    "    # Fill the Viterbi table for the rest of the sentence\n",
    "    for t in range(1, n):\n",
    "        for tag in tag_set:\n",
    "            max_prob = 0\n",
    "            best_prev_tag = None\n",
    "            for prev_tag in tag_set:\n",
    "                prob = (\n",
    "                    viterbi[t - 1][prev_tag]  # Probability of the previous state\n",
    "                    * transition_probs.get(prev_tag, {}).get(tag, 1e-10)  # Transition probability\n",
    "                    * emission_probs.get(tag, {}).get(sentence[t], 1e-10)  # Emission probability\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    best_prev_tag = prev_tag\n",
    "            viterbi[t][tag] = max_prob\n",
    "            backpointer[t][tag] = best_prev_tag\n",
    "\n",
    "    # Backtrack to find the best tag sequence\n",
    "    best_final_tag = max(tag_set, key=lambda tag: viterbi[n - 1][tag])\n",
    "    best_tags = [best_final_tag]\n",
    "\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_tags.insert(0, backpointer[t][best_tags[0]])\n",
    "\n",
    "    return list(zip(sentence, best_tags))\n",
    "\n",
    "# Step (c)iii: Run the Viterbi algorithm on the test set and evaluate\n",
    "correct = 0\n",
    "total = 0\n",
    "known_correct = 0\n",
    "known_total = 0\n",
    "unknown_correct = 0\n",
    "unknown_total = 0\n",
    "\n",
    "all_tags = set(tag_counts.keys())\n",
    "\n",
    "for sentence in test_data:\n",
    "    words = [word for word, tag in sentence]\n",
    "    true_tags = [tag for word, tag in sentence]\n",
    "\n",
    "    # Predict tags using the Viterbi algorithm\n",
    "    predicted_tags = [tag for word, tag in viterbi_algorithm(words, all_tags, transition_probs, emission_probs)]\n",
    "\n",
    "    # Evaluate\n",
    "    for word, true_tag, predicted_tag in zip(words, true_tags, predicted_tags):\n",
    "        total += 1\n",
    "        if true_tag == predicted_tag:\n",
    "            correct += 1\n",
    "\n",
    "        if word in emission_probs:\n",
    "            known_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                known_correct += 1\n",
    "        else:\n",
    "            unknown_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                unknown_correct += 1"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:36:20.247775Z",
     "start_time": "2024-12-18T13:36:20.245641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Calculate error rates\n",
    "known_error_rate = 1 - (known_correct / known_total)\n",
    "unknown_error_rate = 1 - (unknown_correct / unknown_total)\n",
    "total_error_rate = 1 - (known_correct + unknown_correct) / (known_total + unknown_total)\n",
    "\n",
    "# Print results\n",
    "print(f\"Known Words Error Rate: {known_error_rate:.4f}\")\n",
    "print(f\"Unknown Words Error Rate: {unknown_error_rate:.4f}\")\n",
    "print(f\"Total Error Rate: {total_error_rate:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Words Error Rate: 0.0130\n",
      "Unknown Words Error Rate: 0.1482\n",
      "Total Error Rate: 0.1317\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Known Words Error Rate: 0.0130\n",
    "Unknown Words Error Rate: 0.1482\n",
    "Total Error Rate: 0.1317\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:32:22.334453Z",
     "start_time": "2024-12-18T13:30:48.804317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Step (d)i: Training phase with Add-one smoothing for emission probabilities\n",
    "# Count tag occurrences and word-tag pair occurrences\n",
    "emission_counts = defaultdict(lambda: defaultdict(int))  # Counts of (word, tag)\n",
    "tag_counts = defaultdict(int)  # Counts of individual tags\n",
    "vocabulary = set()  # Vocabulary of words in the training data\n",
    "\n",
    "for sentence in train_data:\n",
    "    for word, tag in sentence:\n",
    "        tag_counts[tag] += 1\n",
    "        emission_counts[tag][word] += 1\n",
    "        vocabulary.add(word)\n",
    "\n",
    "# Compute emission probabilities with Add-one smoothing\n",
    "emission_probs_smoothed = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for tag, words in emission_counts.items():\n",
    "    # Total number of words emitted by the tag (with smoothing)\n",
    "    total_emissions = tag_counts[tag] + len(vocabulary)  # Add-one smoothing\n",
    "\n",
    "    for word in vocabulary:\n",
    "        # Add-one smoothed emission probability for known words\n",
    "        emission_probs_smoothed[tag][word] = (emission_counts[tag][word] + 1) / total_emissions\n",
    "\n",
    "    # Add-one smoothed probability for unknown words\n",
    "    emission_probs_smoothed[tag][\"<UNK>\"] = 1 / total_emissions\n",
    "\n",
    "# Step (d)ii: Run the modified Viterbi algorithm on the test set\n",
    "def viterbi_with_smoothing(sentence, tag_set, transition_probs, emission_probs_smoothed, unknown_tag='NN'):\n",
    "    \"\"\"\n",
    "    Perform POS tagging using the Viterbi algorithm with smoothed emission probabilities.\n",
    "    \"\"\"\n",
    "    n = len(sentence)\n",
    "    viterbi = [{} for _ in range(n)]  # Viterbi table: list of dictionaries\n",
    "    backpointer = [{} for _ in range(n)]  # Backpointer table: list of dictionaries\n",
    "\n",
    "    # Initialization for the first word\n",
    "    for tag in tag_set:\n",
    "        viterbi[0][tag] = (\n",
    "            transition_probs.get(None, {}).get(tag, 1e-10)  # Start transition probability\n",
    "            * emission_probs_smoothed.get(tag, {}).get(sentence[0], emission_probs_smoothed[tag][\"<UNK>\"])  # Smoothed emission\n",
    "        )\n",
    "        backpointer[0][tag] = None\n",
    "\n",
    "    # Fill the Viterbi table for the rest of the sentence\n",
    "    for t in range(1, n):\n",
    "        for tag in tag_set:\n",
    "            max_prob = 0\n",
    "            best_prev_tag = None\n",
    "            for prev_tag in tag_set:\n",
    "                prob = (\n",
    "                    viterbi[t - 1][prev_tag]  # Probability of the previous state\n",
    "                    * transition_probs.get(prev_tag, {}).get(tag, 1e-10)  # Transition probability\n",
    "                    * emission_probs_smoothed.get(tag, {}).get(sentence[t], emission_probs_smoothed[tag][\"<UNK>\"])  # Smoothed emission\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    best_prev_tag = prev_tag\n",
    "            viterbi[t][tag] = max_prob\n",
    "            backpointer[t][tag] = best_prev_tag\n",
    "\n",
    "    # Backtrack to find the best tag sequence\n",
    "    best_final_tag = max(tag_set, key=lambda tag: viterbi[n - 1][tag])\n",
    "    best_tags = [best_final_tag]\n",
    "\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_tags.insert(0, backpointer[t][best_tags[0]])\n",
    "\n",
    "    return list(zip(sentence, best_tags))\n",
    "\n",
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "known_correct = 0\n",
    "known_total = 0\n",
    "unknown_correct = 0\n",
    "unknown_total = 0\n",
    "\n",
    "for sentence in test_data:\n",
    "    words = [word for word, tag in sentence]\n",
    "    true_tags = [tag for word, tag in sentence]\n",
    "\n",
    "    # Predict tags using the Viterbi algorithm with smoothed emission probabilities\n",
    "    predicted_tags = [tag for word, tag in viterbi_with_smoothing(words, all_tags, transition_probs, emission_probs_smoothed)]\n",
    "\n",
    "    # Evaluate\n",
    "    for word, true_tag, predicted_tag in zip(words, true_tags, predicted_tags):\n",
    "        total += 1\n",
    "        if true_tag == predicted_tag:\n",
    "            correct += 1\n",
    "\n",
    "        if word in vocabulary:\n",
    "            known_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                known_correct += 1\n",
    "        else:\n",
    "            unknown_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                unknown_correct += 1\n",
    "\n",
    "# Calculate error rates\n",
    "known_error_rate = 1 - (known_correct / known_total)\n",
    "unknown_error_rate = 1 - (unknown_correct / unknown_total)\n",
    "total_error_rate = 1 - (correct / total)\n",
    "\n",
    "# Print results\n",
    "print(f\"Known Words Error Rate: {known_error_rate:.4f}\")\n",
    "print(f\"Unknown Words Error Rate: {unknown_error_rate:.4f}\")\n",
    "print(f\"Total Error Rate: {total_error_rate:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Words Error Rate: 0.1813\n",
      "Unknown Words Error Rate: 0.7609\n",
      "Total Error Rate: 0.2475\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:39:33.012432Z",
     "start_time": "2024-12-18T13:39:33.008589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Known Words Error Rate: 0.1813\n",
    "Unknown Words Error Rate: 0.7609\n",
    "Total Error Rate: 0.2475\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKnown Words Error Rate: 0.1813\\nUnknown Words Error Rate: 0.7609\\nTotal Error Rate: 0.2475\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:02:09.382683Z",
     "start_time": "2024-12-18T14:02:09.276162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_pseudo_word(word):\n",
    "    \"\"\"\n",
    "    Categorize words into pseudo-words based on patterns.\n",
    "    \"\"\"\n",
    "    if re.match(r'^[A-Z][a-z]*$', word):  # Proper noun\n",
    "        return \"<CAPITALIZED>\"\n",
    "    elif re.match(r'^[0-9]+$', word):  # Numeric\n",
    "        return \"<NUMERIC>\"\n",
    "    elif re.match(r'.*ing$', word):  # Gerund\n",
    "        return \"<GERUND>\"\n",
    "    elif re.match(r'.*ed$', word):  # Past tense\n",
    "        return \"<PAST>\"\n",
    "    elif re.match(r'.*s$', word):  # Plural\n",
    "        return \"<PLURAL>\"\n",
    "    elif re.match(r'[!?.]$', word):  # Punctuation\n",
    "        return \"<PUNCTUATION>\"\n",
    "    else:  # General unknown\n",
    "        return \"<UNKNOWN>\"\n",
    "\n",
    "# Threshold for low-frequency words\n",
    "low_freq_threshold = 2^30\n",
    "word_counts = defaultdict(int)\n",
    "\n",
    "# Count word frequencies\n",
    "for sentence in train_data:\n",
    "    for word, tag in sentence:\n",
    "        word_counts[word] += 1\n",
    "\n",
    "# Replace low-frequency words and unknown words with pseudo-words\n",
    "train_data_pseudo = [\n",
    "    [\n",
    "        (word if word_counts[word] > low_freq_threshold else get_pseudo_word(word), tag)\n",
    "        for word, tag in sentence\n",
    "    ]\n",
    "    for sentence in train_data\n",
    "]\n",
    "\n",
    "# Build the vocabulary of frequent words\n",
    "vocabulary_pseudo = {word for word in word_counts if word_counts[word] > low_freq_threshold}\n"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:03:32.047932Z",
     "start_time": "2024-12-18T14:02:10.732223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Train the model using pseudo-words\n",
    "emission_counts_pseudo = defaultdict(lambda: defaultdict(int))\n",
    "tag_counts_pseudo = defaultdict(int)\n",
    "\n",
    "for sentence in train_data_pseudo:\n",
    "    for word, tag in sentence:\n",
    "        tag_counts_pseudo[tag] += 1\n",
    "        emission_counts_pseudo[tag][word] += 1\n",
    "\n",
    "# Compute emission probabilities for pseudo-words\n",
    "emission_probs_pseudo = defaultdict(lambda: defaultdict(float))\n",
    "for tag, words in emission_counts_pseudo.items():\n",
    "    total_emissions = sum(words.values())\n",
    "    for word, count in words.items():\n",
    "        emission_probs_pseudo[tag][word] = count / total_emissions\n",
    "\n",
    "# Step 2: Replace unknown words in the test set with pseudo-words\n",
    "test_data_pseudo = [\n",
    "    [\n",
    "        (word if word in vocabulary_pseudo else get_pseudo_word(word), tag)\n",
    "        for word, tag in sentence\n",
    "    ]\n",
    "    for sentence in test_data\n",
    "]\n",
    "\n",
    "# Step 3: Run Viterbi with pseudo-words\n",
    "correct, total = 0, 0\n",
    "known_correct, known_total = 0, 0\n",
    "unknown_correct, unknown_total = 0, 0\n",
    "\n",
    "for sentence in test_data_pseudo:\n",
    "    words = [word for word, tag in sentence]\n",
    "    true_tags = [tag for word, tag in sentence]\n",
    "\n",
    "    predicted_tags = [\n",
    "        tag for word, tag in viterbi_algorithm(words, all_tags, transition_probs, emission_probs_pseudo)\n",
    "    ]\n",
    "\n",
    "    for word, true_tag, predicted_tag in zip(words, true_tags, predicted_tags):\n",
    "        total += 1\n",
    "        if true_tag == predicted_tag:\n",
    "            correct += 1\n",
    "\n",
    "        if word in vocabulary_pseudo:\n",
    "            known_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                known_correct += 1\n",
    "        else:\n",
    "            unknown_total += 1\n",
    "            if true_tag == predicted_tag:\n",
    "                unknown_correct += 1\n",
    "\n",
    "# Compute error rates\n",
    "known_error_rate = 1 - (known_correct / known_total)\n",
    "unknown_error_rate = 1 - (unknown_correct / unknown_total)\n",
    "total_error_rate = 1 - (correct / total)\n",
    "\n",
    "print(f\"(e)ii) Known Words Error Rate: {known_error_rate:.4f}\")\n",
    "print(f\"(e)ii) Unknown Words Error Rate: {unknown_error_rate:.4f}\")\n",
    "print(f\"(e)ii) Total Error Rate: {total_error_rate:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(e)ii) Known Words Error Rate: 0.0460\n",
      "(e)ii) Unknown Words Error Rate: 0.3959\n",
      "(e)ii) Total Error Rate: 0.1959\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "(e)ii) Known Words Error Rate: 0.0472\n",
    "(e)ii) Unknown Words Error Rate: 0.3762\n",
    "(e)ii) Total Error Rate: 0.1311\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-18T14:15:27.446202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Apply Add-One Smoothing to Pseudo-Words\n",
    "emission_probs_smoothed_pseudo = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for tag, words in emission_counts_pseudo.items():\n",
    "    total_emissions = tag_counts_pseudo[tag] + len(vocabulary_pseudo)  # Add-one smoothing\n",
    "    for word in vocabulary_pseudo:\n",
    "        emission_probs_smoothed_pseudo[tag][word] = (emission_counts_pseudo[tag][word] + 1) / total_emissions\n",
    "    emission_probs_smoothed_pseudo[tag][\"<UNK>\"] = 1 / total_emissions\n",
    "\n",
    "# Step 2: Run Viterbi with pseudo-words and smoothed probabilities\n",
    "correct, total = 0, 0\n",
    "confusion_matrix = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sentence in test_data_pseudo:\n",
    "    words = [word for word, tag in sentence]\n",
    "    true_tags = [tag for word, tag in sentence]\n",
    "\n",
    "    predicted_tags = [\n",
    "        tag for word, tag in viterbi_with_smoothing(words, all_tags, transition_probs, emission_probs_smoothed_pseudo)\n",
    "    ]\n",
    "\n",
    "    for word, true_tag, predicted_tag in zip(words, true_tags, predicted_tags):\n",
    "        total += 1\n",
    "        confusion_matrix[true_tag][predicted_tag] += 1\n",
    "        if true_tag == predicted_tag:\n",
    "            correct += 1\n",
    "\n",
    "# Compute error rates\n",
    "total_error_rate = 1 - (correct / total)\n",
    "\n",
    "print(f\"(e)iii) Total Error Rate: {total_error_rate:.4f}\")\n",
    "\n",
    "# Step 3: Build and Investigate the Confusion Matrix\n",
    "tags_list = sorted(all_tags)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':10s} {' '.join(f'{tag:5s}' for tag in tags_list)}\")\n",
    "for true_tag in tags_list:\n",
    "    row = [confusion_matrix[true_tag].get(predicted_tag, 0) for predicted_tag in tags_list]\n",
    "    print(f\"{true_tag:10s} {' '.join(f'{val:5d}' for val in row)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
